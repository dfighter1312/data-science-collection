{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ee200a-a60d-41b9-9015-6306347937f0",
   "metadata": {},
   "source": [
    "# PySpark for Social Bot Detection (Twibot-22 benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801be47f-a823-4fd5-a139-f1a54f21b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 17:09:39 WARN Utils: Your hostname, Mufins-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.3.56 instead (on interface en0)\n",
      "23/04/14 17:09:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 17:09:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession from builder\n",
    "# If the sample data you work with is small, you can remove the `.config` call\n",
    "spark = SparkSession.builder.appName('Spark') \\\n",
    "            .config(\"spark.driver.memory\", \"10g\") \\\n",
    "            .config(\"spark.driver.maxResultSize\", \"3g\") \\\n",
    "            .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c26c00-2d38-40c4-809d-32c747be2854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "small_tweet_df = spark.read.json('partitioned/tweet_1_par_1.json')\n",
    "tweet_schema_small = small_tweet_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee336e49-15aa-4020-822f-d47b3d7d53a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- attachments: struct (nullable = true)\n",
      " |    |-- media_keys: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- poll_ids: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- context_annotations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- domain: struct (nullable = true)\n",
      " |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- entity: struct (nullable = true)\n",
      " |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |-- conversation_id: long (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- annotations: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- end: long (nullable = true)\n",
      " |    |    |    |-- normalized_text: string (nullable = true)\n",
      " |    |    |    |-- probability: string (nullable = true)\n",
      " |    |    |    |-- start: long (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |-- cashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- end: long (nullable = true)\n",
      " |    |    |    |-- start: long (nullable = true)\n",
      " |    |    |    |-- tag: string (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- end: long (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- start: long (nullable = true)\n",
      " |    |    |    |-- tag: string (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- end: long (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- start: long (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |    |-- symbols: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- end: long (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- images: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- start: long (nullable = true)\n",
      " |    |    |    |-- status: long (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- unwound_url: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |-- geo: struct (nullable = true)\n",
      " |    |-- coordinates: string (nullable = true)\n",
      " |    |-- place_id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_user_id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- possibly_sensitive: boolean (nullable = true)\n",
      " |-- public_metrics: struct (nullable = true)\n",
      " |    |-- like_count: long (nullable = true)\n",
      " |    |-- quote_count: long (nullable = true)\n",
      " |    |-- reply_count: long (nullable = true)\n",
      " |    |-- retweet_count: long (nullable = true)\n",
      " |-- referenced_tweets: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- reply_settings: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- withheld: struct (nullable = true)\n",
      " |    |-- copyright: boolean (nullable = true)\n",
      " |    |-- country_codes: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- scope: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "small_tweet_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ddca2b-4f98-40ab-b238-78d7ced3ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attachments: struct<media_keys:array<string>,poll_ids:array<string>>, author_id: bigint, context_annotations: array<struct<domain:struct<description:string,id:string,name:string>,entity:struct<description:string,id:string,name:string>>>, conversation_id: bigint, created_at: string, entities: struct<annotations:array<struct<end:bigint,normalized_text:string,probability:string,start:bigint,type:string>>,cashtags:array<struct<end:bigint,start:bigint,tag:string>>,hashtags:array<struct<end:bigint,indices:array<bigint>,start:bigint,tag:string,text:string>>,media:array<struct<display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array<bigint>,media_url:string,media_url_https:string,sizes:struct<large:struct<h:bigint,resize:string,w:bigint>,medium:struct<h:bigint,resize:string,w:bigint>,small:struct<h:bigint,resize:string,w:bigint>,thumb:struct<h:bigint,resize:string,w:bigint>>,source_status_id:bigint,source_status_id_str:string,source_user_id:bigint,source_user_id_str:string,type:string,url:string>>,mentions:array<struct<end:bigint,id:string,start:bigint,username:string>>,symbols:array<struct<indices:array<bigint>,text:string>>,urls:array<struct<description:string,display_url:string,end:bigint,expanded_url:string,images:array<struct<height:bigint,url:string,width:bigint>>,indices:array<bigint>,start:bigint,status:bigint,title:string,unwound_url:string,url:string>>,user_mentions:array<struct<id:bigint,id_str:string,indices:array<bigint>,name:string,screen_name:string>>>, geo: struct<coordinates:string,place_id:string,type:string>, id: string, in_reply_to_user_id: bigint, lang: string, possibly_sensitive: boolean, public_metrics: struct<like_count:bigint,quote_count:bigint,reply_count:bigint,retweet_count:bigint>, referenced_tweets: array<struct<id:string,type:string>>, reply_settings: string, source: string, text: string, withheld: struct<copyright:boolean,country_codes:array<string>,scope:string>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tweet_df = spark.read.json('partitioned/tweet_1_par_1.json', schema=tweet_schema_small)\n",
    "full_tweet_df.na.drop(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528d6fed-8243-4bbb-93a5-02857e15b75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|           source_id| relation|           target_id|\n",
      "+--------------------+---------+--------------------+\n",
      "| u980749991491682304|followers|u1480979504696864775|\n",
      "|          u105387876|following|          u402576793|\n",
      "|          u148520716|following|           u59653593|\n",
      "|u1276438425457967110|following|u1389155636693381120|\n",
      "|u1445432327367237638|following| u848348952084828160|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edge_df = spark.read.csv('edge.csv', header=True)\n",
    "edge_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa846f6-6930-4152-b8b8-d8d19a972c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===============================================>         (42 + 8) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  relation|\n",
      "+----------+\n",
      "| followers|\n",
      "| following|\n",
      "|       own|\n",
      "|    pinned|\n",
      "|      post|\n",
      "|   contain|\n",
      "|   discuss|\n",
      "| mentioned|\n",
      "|  followed|\n",
      "|      like|\n",
      "|    quoted|\n",
      "| retweeted|\n",
      "|replied_to|\n",
      "|membership|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edge_df.select('relation').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c25fad-8a43-4d83-8e5d-65b8bef25b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, LongType\n",
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "\n",
    "def preprocessing(row):\n",
    "    URL_PATTERN = r\"[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "    rowlist = str(row).split()\n",
    "    rowlist = [word.strip() for word in rowlist]\n",
    "    rowlist = [word if not word.strip().startswith(\n",
    "        '#') else \"hashtagtag\" for word in rowlist]\n",
    "    rowlist = [word if not word.strip().startswith(\n",
    "        '@') else \"usertag\" for word in rowlist]\n",
    "    rowlist = [word.lower() for word in rowlist]\n",
    "    rowlist = [re.sub(URL_PATTERN, \"urltag\", word) for word in rowlist]\n",
    "    return \" \".join(rowlist)\n",
    "\n",
    "udfPreprocessing = F.udf(preprocessing, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6864a446-741b-448e-8ebe-33c71b498314",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets = full_tweet_df.withColumn(\"preprocessed_text\", udfPreprocessing(F.col(\"text\"))).select([\"preprocessed_text\", \"author_id\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efbab990-3a74-4ca7-8b3b-b8e51660a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"preprocessed_text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "tfidfData = pipeline.fit(preprocessed_tweets).transform(preprocessed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ac929a-fa75-4d55-87fe-2beadcc6281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = spark.read.csv(\"label.csv\", header=True)\n",
    "idProcessing = F.udf(lambda x: int(x[1:]), LongType())\n",
    "label_df = label_df.withColumn(\"author_id\", idProcessing(F.col(\"id\")))\n",
    "label_df = label_df.withColumn(\"label_bool\", F.col(\"label\") == \"bot\")\n",
    "label_df = label_df.withColumn(\"label_int\", F.col(\"label_bool\").cast(\"integer\"))\n",
    "label_df = label_df.select(F.col(\"author_id\"), F.col(\"label_int\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b03fe4-8ec3-4487-815e-59906b45a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfData_ = tfidfData.join(label_df, on=\"author_id\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b525089d-7cc8-4607-b4e5-a514d4c7fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|          author_id|label|\n",
      "+-------------------+-----+\n",
      "|1217628182611927040|    0|\n",
      "|         2664730894|    0|\n",
      "|1266703520205549568|    0|\n",
      "|1089159225148882949|    0|\n",
      "|           36741729|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2398bc72-e908-419a-b710-531b1f43a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- preprocessed_text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfData_.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89112f8c-1ccc-4d50-850f-633f3411964a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join_1_df = tfidfData.join(edge_df, tfidfData[\"id\"] == edge_df[\"source_id\"], how='left')\n",
    "# join_full_df = join_1_df.join(tfidfData.withColumnRenamed(\"features\", \"referenced_features\").withColumnRenamed(\"id\", \"referenced_id\").withColumnRenamed(\"author_id\", \"referenced_author_id\").alias(\"b\"), F.col(\"a.target_id\") == F.col(\"b.referenced_id\"), how='left')\n",
    "temp_df = tfidfData_.join(edge_df, tfidfData_[\"id\"] == edge_df[\"source_id\"], how=\"left\")\n",
    "output_df = temp_df.alias(\"tfidf1\").join(tfidfData_.alias(\"tfidf2\"), F.col(\"tfidf1.target_id\") == F.col(\"tfidf2.id\"), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0468b0-a20d-48a7-9eda-0db942ae3891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- preprocessed_text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- relation: string (nullable = true)\n",
      " |-- target_id: string (nullable = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- preprocessed_text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3758f463-49dc-4215-8664-471783814079",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df.select(\n",
    "    F.col(\"tfidf1.author_id\").alias(\"source_author_id\"),\n",
    "    F.col(\"tfidf1.label\").alias(\"source_label\"),\n",
    "    F.col(\"tfidf1.features\").alias(\"source_features\"),\n",
    "    F.col(\"relation\"),\n",
    "    F.col(\"tfidf2.author_id\").alias(\"target_author_id\"),\n",
    "    F.col(\"tfidf2.label\").alias(\"target_label\"),\n",
    "    F.col(\"tfidf2.features\").alias(\"target_features\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6984991-5ce9-4e70-9503-4a0f337a4fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source_author_id: bigint, source_label: int, source_features: vector, relation: string, target_author_id: bigint, target_label: int, target_features: vector]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea9f446-c53a-4955-9fc4-4b819e55acda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b59a7f-8c9e-4831-b0c3-04f2a7b247c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_user_id = output_df.select(\"source_author_id\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "len(distinct_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5dcf71-6451-4a2c-b958-194f293b3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def convert_sparse_vectors_to_tensor(sparse_vectors_list):\n",
    "    # get the number of rows and columns of the sparse vectors\n",
    "    num_rows = sparse_vectors_list[0].size\n",
    "    num_cols = len(sparse_vectors_list)\n",
    "\n",
    "    # create a list of tuples (i, j, v) containing the non-zero entries of the sparse vectors\n",
    "    non_zero_entries = []\n",
    "    for j, sparse_vector in enumerate(sparse_vectors_list):\n",
    "        for i, v in zip(sparse_vector.indices, sparse_vector.values):\n",
    "            non_zero_entries.append((i, j, v))\n",
    "\n",
    "    # create a SciPy COO sparse matrix from the non-zero entries\n",
    "    coo_mat = coo_matrix((np.array([entry[2] for entry in non_zero_entries]),\n",
    "                          (np.array([entry[0] for entry in non_zero_entries]),\n",
    "                           np.array([entry[1] for entry in non_zero_entries]))),\n",
    "                          shape=(num_rows, num_cols))\n",
    "\n",
    "    # create a PyTorch sparse tensor from the SciPy COO sparse matrix\n",
    "    torch_sparse_tensor = torch.sparse_coo_tensor(torch.LongTensor([coo_mat.row.tolist(), coo_mat.col.tolist()]),\n",
    "                                                  torch.FloatTensor(coo_mat.data.astype(np.float32)),\n",
    "                                                  torch.Size(coo_mat.shape))\n",
    "\n",
    "    # convert the PyTorch sparse tensor to a dense tensor\n",
    "    torch_dense_tensor = torch_sparse_tensor.to_dense().T\n",
    "    \n",
    "    return torch_dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4f8171e-5e7a-4899-bafc-143151e13ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1293/1293 [02:34<00:00,  8.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a torch tweet tensor for every user\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tweets_torch = []\n",
    "tweet_labels_torch = []\n",
    "relationships = []\n",
    "owned_tweets_indicator = []\n",
    "\n",
    "users = pd.read_csv('label.csv')\n",
    "# for user_id in tqdm(users['id']):\n",
    "for user_id in tqdm(distinct_user_id):\n",
    "# if True:\n",
    "    # user_id = int(user_id[1:])\n",
    "    tweets_from_user = output_df.filter(output_df[\"source_author_id\"] == user_id)\n",
    "    # print(user_id)\n",
    "    # tweets_from_user = output_df.filter(output_df[\"source_author_id\"] == 3078703231)\n",
    "    tweets_from_user_df = tweets_from_user.toPandas()\n",
    "    tweet_count = len(tweets_from_user_df)\n",
    "\n",
    "    owned_tweets = tweets_from_user_df[\"source_features\"]\n",
    "    referenced_tweets = tweets_from_user_df[\"target_features\"].dropna()\n",
    "\n",
    "    owned_labels = tweets_from_user_df[\"source_label\"]\n",
    "    referenced_labels = tweets_from_user_df[\"target_label\"].dropna()\n",
    "\n",
    "    ref_tweet_count = len(referenced_tweets)\n",
    "    ref_label_count = len(referenced_labels)\n",
    "    owned_tweet_count = len(owned_tweets)\n",
    "    assert ref_tweet_count == ref_label_count\n",
    "\n",
    "    # tfidf_array_owned = owned_tweets.rdd.flatMap(lambda x: x).collect()\n",
    "    if ref_tweet_count != 0:\n",
    "        # tfidf_array_referenced = referenced_tweets.rdd.flatMap(lambda x: x).collect()\n",
    "        # tweets_torch.append(torch.tensor(tfidf_array_owned + tfidf_array_referenced))\n",
    "        tweets_torch.append(convert_sparse_vectors_to_tensor(owned_tweets.tolist() + referenced_tweets.tolist()))\n",
    "    elif tweet_count != 0:\n",
    "        # tweets_torch.append(torch.tensor(tfidf_array_owned))\n",
    "        tweets_torch.append(convert_sparse_vectors_to_tensor(owned_tweets.tolist()))\n",
    "    else:\n",
    "        tweets_torch.append(torch.empty([0, 50000]))\n",
    "\n",
    "    # label_array_owned = owned_labels.rdd.flatMap(lambda x: x).collect()\n",
    "    if ref_label_count != 0:\n",
    "        # label_array_referenced = referenced_labels.rdd.flatMap(lambda x: x).collect()\n",
    "        tweet_labels_torch.append(torch.tensor(owned_labels.tolist() + referenced_labels.tolist()))\n",
    "    elif tweet_count != 0:\n",
    "        tweet_labels_torch.append(torch.tensor(owned_labels.tolist()))\n",
    "    else:\n",
    "        tweet_labels_torch.append(torch.tensor([]))\n",
    "\n",
    "    if ref_tweet_count != 0:\n",
    "        # tweets_from_user = tweets_from_user.withColumn(\"origin_tweet_new_id\", F.monotonically_increasing_id())\n",
    "        # max_tweet_id = tweets_from_user.agg({\"x\": \"max\"}).collect()[0]\n",
    "        # tweets_from_user = tweets_from_user.dropna(subset=\"target_features\")\n",
    "        # tweets_from_user = tweets_from_user.withColumn(\"referenced_tweet_new_id\", max_tweet_id + F.monotonically_increasing_id())\n",
    "        # tweets_from_user = tweets_from_user.select([\"origin_tweet_new_id\"])\n",
    "        # rel_array = owned_tweets.rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "        tweets_from_user_df[\"origin_tweet_new_id\"] = tweets_from_user_df.index\n",
    "        max_tweet_id = max(tweets_from_user_df.index)\n",
    "        tweets_from_user_df = tweets_from_user_df.dropna(subset=\"target_features\").reset_index()\n",
    "        tweets_from_user_df[\"referenced_tweet_new_id\"] = tweets_from_user_df.index + max_tweet_id + 1\n",
    "        rel_array = [(i, j) for _, (i, j) in tweets_from_user_df[[\"origin_tweet_new_id\", \"referenced_tweet_new_id\"]].iterrows()]\n",
    "\n",
    "        relationships.append(torch.tensor(rel_array))\n",
    "        \n",
    "        yes_temp = [1] * (max_tweet_id + 1)\n",
    "        no_temp = [0] * len(tweets_from_user_df)\n",
    "        full_temp = yes_temp + no_temp\n",
    "        owned_tweets_indicator.append(torch.tensor(full_temp))\n",
    "    else:\n",
    "        relationships.append(torch.empty([0, 2]))\n",
    "        owned_tweets_indicator.append(torch.tensor([1] * owned_tweet_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83caaa8c-086d-411a-9e4a-cd44b4983934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b1d5fb4-43df-40d6-987c-50646af619fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariedDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, torch_list):\n",
    "        self.torch_list = torch_list\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError(f\"Index exceeds length of the dataset of {len(self)}\")\n",
    "        return self.torch_list[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.torch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58425fee-f7ff-4633-8ffd-5b5262092ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    \"\"\"\n",
    "    Padds batch of variable length\n",
    "\n",
    "    Note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    \"\"\"\n",
    "    ## Get sequence lengths\n",
    "    lengths = [t.shape[0] for t in batch]\n",
    "    print(lengths)\n",
    "    print(batch[0].shape)\n",
    "    try:\n",
    "        n_features = batch[0].shape[1]\n",
    "        print(n_features)\n",
    "    except:\n",
    "        n_features = 1\n",
    "    max_length = max(lengths)\n",
    "    if max_length == 0:\n",
    "        max_length += 1\n",
    "    batch_size = len(lengths)\n",
    "\n",
    "    padded_tensor = torch.zeros(batch_size, max_length, n_features, dtype=torch.float32)\n",
    "    for i, val in enumerate(batch):\n",
    "        l = lengths[i]\n",
    "        padded_tensor[i, :l] = val\n",
    "    \n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "297b15ba-d660-4390-bff2-9b563e45ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing max_id_user_tweet_rela\n",
    "dataset = VariedDataset(owned_tweets_indicator)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=collate_fn_padd)\n",
    "torch.save(dataloader, \"dataloaders/sample/user_tweet_ind.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614ec12-c8d3-4a2a-8461-5e835ba384dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VariedDataset(tweets_torch)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=collate_fn_padd)\n",
    "torch.save(dataloader, \"dataloaders/sample/tweet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c83cad-c67d-4a73-97cb-6ba7a5a918bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VariedDataset(tweet_labels_torch)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=collate_fn_padd)\n",
    "torch.save(dataloader, \"dataloaders/sample/tweet_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab0112-6ba2-42dd-a9eb-617c7b2ef391",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VariedDataset(relationships)\n",
    "dataloader = DataLoader(relationships, batch_size=8, collate_fn=collate_fn_padd)\n",
    "torch.save(dataloader, \"dataloaders/sample/relationships.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d26be1-33f7-4a02-8c3b-b212ac8ae8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_sample_df = pd.DataFrame(distinct_user_id, columns=['id'])\n",
    "user_sample_df[\"id\"] = \"u\" + user_sample_df[\"id\"].astype('str')\n",
    "user_sample_df.to_csv(\"sample_user.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f9359-5d1a-4e07-9f1b-62ff9ae1fea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
