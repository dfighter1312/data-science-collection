{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f943f6-723c-4943-b101-3f041c0afd14",
   "metadata": {
    "id": "f5f943f6-723c-4943-b101-3f041c0afd14"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 40)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154efbe-1521-46b3-ab52-ff30d0b2ddc3",
   "metadata": {
    "id": "7154efbe-1521-46b3-ab52-ff30d0b2ddc3",
    "outputId": "855c8041-8b2f-4790-f693-c2f6960d5413"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('full.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c60860-5d4e-4ed8-b191-79b4174afb7c",
   "metadata": {
    "id": "72c60860-5d4e-4ed8-b191-79b4174afb7c",
    "outputId": "562cc73d-26f1-4442-af4c-a20382c374cc"
   },
   "outputs": [],
   "source": [
    "df.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039bb1a-a475-482a-8c5e-1ad1081f3eb5",
   "metadata": {
    "id": "9039bb1a-a475-482a-8c5e-1ad1081f3eb5"
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, input_cols, target_col, input_horizon, output_horizon):\n",
    "        total_horizon = input_horizon + output_horizon\n",
    "        list_features = []\n",
    "        for col in input_cols:\n",
    "            if col not in df.columns:\n",
    "                print(f\"Column {col} is not found, skipping.\")\n",
    "                continue\n",
    "            series = df[col]\n",
    "            merged_series = pd.concat([series.diff(periods=i) for i in range(total_horizon)], axis=1).dropna()\n",
    "            inp = np.expand_dims(merged_series.values[:, :input_horizon], 1)\n",
    "            list_features.append(inp)\n",
    "            if col == target_col:\n",
    "                self.tar = merged_series.values[:, -output_horizon:]\n",
    "                print(self.tar.shape)\n",
    "        self.inp = np.concatenate(list_features, axis=1)\n",
    "        print(self.inp.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = torch.from_numpy(self.inp[idx]).float()\n",
    "        tar = torch.from_numpy(self.tar[idx]).float()\n",
    "        return inp, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980984ef-6b06-4e36-a543-967ed918e6f0",
   "metadata": {
    "id": "980984ef-6b06-4e36-a543-967ed918e6f0",
    "outputId": "f0fbf427-da3f-4677-b429-35f7cc1299cf"
   },
   "outputs": [],
   "source": [
    "input_horizon = 24\n",
    "output_horizon = 48\n",
    "# Randomly choose 3 features with the original one\n",
    "input_cols=['Lộ 173 | P', 'Lộ 173 | Q']\n",
    "target_col='Lộ 173 | P'\n",
    "n_channels = len(input_cols)\n",
    "\n",
    "single_dataset = TimeSeriesDataset(\n",
    "    df,\n",
    "    input_cols=['Lộ 173 | P', 'Lộ 173 | Q'],\n",
    "    target_col='Lộ 173 | P',\n",
    "    input_horizon=input_horizon,\n",
    "    output_horizon=output_horizon\n",
    ")\n",
    "train_size = int(0.8 * len(single_dataset))\n",
    "test_size = len(single_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    single_dataset,\n",
    "    [train_size, test_size]\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde876d-4b1e-4e8d-8521-89b242dbd4f3",
   "metadata": {
    "id": "4dde876d-4b1e-4e8d-8521-89b242dbd4f3"
   },
   "outputs": [],
   "source": [
    "def get_historical_attributes(series, input_timesteps, output_timesteps):\n",
    "    df = pd.DataFrame()\n",
    "    n_features = input_timesteps + output_timesteps\n",
    "    for i in range(n_features):\n",
    "        df[f'lag-{i}'] = series.shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    past_df = df.iloc[:, -input_timesteps:]\n",
    "    future_df = df.iloc[:, :output_timesteps]\n",
    "    return past_df, future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb270e-7b53-4574-8b86-ca74e33f8bd8",
   "metadata": {
    "id": "d4bb270e-7b53-4574-8b86-ca74e33f8bd8"
   },
   "outputs": [],
   "source": [
    "INPUT_TIMESTEPS = 7\n",
    "OUTPUT_TIMESTEPS = 3\n",
    "past_df, future_df = get_historical_attributes(df.iloc[:, 0], INPUT_TIMESTEPS, OUTPUT_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6d75f-4cdb-4a6a-aa3d-9dc352dfc908",
   "metadata": {
    "id": "b2c6d75f-4cdb-4a6a-aa3d-9dc352dfc908",
    "outputId": "51cc5596-b108-4e80-f9e9-f176abbfe2e8"
   },
   "outputs": [],
   "source": [
    "df.iloc[:14, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505158c2-07c6-48fb-9472-85cb93b27630",
   "metadata": {
    "id": "505158c2-07c6-48fb-9472-85cb93b27630",
    "outputId": "64fe201b-cf20-4c0d-f5db-9e2f2a887643"
   },
   "outputs": [],
   "source": [
    "past_df, future_df = get_historical_attributes(df.iloc[:, 0], INPUT_TIMESTEPS, OUTPUT_TIMESTEPS)\n",
    "past_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa572b-7349-4915-8149-6849971c6aa9",
   "metadata": {
    "id": "dbfa572b-7349-4915-8149-6849971c6aa9",
    "outputId": "431d6fd5-7a4a-4162-bef8-e424bbfeba74"
   },
   "outputs": [],
   "source": [
    "future_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dfb4f-e7ac-4bfe-8820-6bf1d48c3da8",
   "metadata": {
    "id": "872dfb4f-e7ac-4bfe-8820-6bf1d48c3da8"
   },
   "outputs": [],
   "source": [
    "class DilatedCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_horizon, output_horizon):\n",
    "        super(DilatedCNN, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=n_channels,\n",
    "                out_channels=n_channels * 2,\n",
    "                kernel_size=2,\n",
    "                dilation=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=n_channels * 2,\n",
    "                out_channels=n_channels * 4,\n",
    "                kernel_size=2,\n",
    "                dilation=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=n_channels * 4,\n",
    "                out_channels=n_channels * 8,\n",
    "                kernel_size=2,\n",
    "                dilation=2,\n",
    "                padding=1\n",
    "            ),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_channels * 8 * input_horizon, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, output_horizon)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97ec7d-f95b-45f7-b702-e6e2703c1b01",
   "metadata": {
    "id": "9a97ec7d-f95b-45f7-b702-e6e2703c1b01"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "eval_dict = {}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def eval_model_multi(model_cls: torch.nn.Module, model_name, epochs=5, **kwargs):\n",
    "    model = model_cls(**kwargs)\n",
    "    model.to(device)\n",
    "    if torch.cuda.device_count() > 0:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    metr = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        loss_records = []\n",
    "        for sample in tqdm(train_dataloader):\n",
    "            model.zero_grad()\n",
    "\n",
    "            inp, tar = sample\n",
    "            inp, tar = inp.to(device), tar.to(device)\n",
    "            pred = model.forward(inp)\n",
    "\n",
    "            loss = loss_fn(pred, tar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_records.append(loss.data.cpu().numpy())\n",
    "\n",
    "            inp, tar = inp.to(\"cpu\"), tar.to(\"cpu\")\n",
    "\n",
    "        print(\"loss: {}\".format(sum(loss_records) / len(loss_records)))\n",
    "\n",
    "    model.eval()\n",
    "    mae_records = []\n",
    "    mse_records = []\n",
    "    for sample in tqdm(test_dataloader):\n",
    "        model.zero_grad()\n",
    "        inp, tar = sample\n",
    "        inp, tar = inp.to(device), tar.to(device)\n",
    "        pred = model.forward(inp)\n",
    "\n",
    "        mse = loss_fn(pred, tar)\n",
    "        mae = metr(pred, tar)\n",
    "\n",
    "        mse_records.append(mse.data.cpu().numpy())\n",
    "        mae_records.append(mae.data.cpu().numpy())\n",
    "\n",
    "        inp, tar = inp.to(\"cpu\"), tar.to(\"cpu\")\n",
    "\n",
    "    eval_dict[model_name] = dict()\n",
    "    eval_dict[model_name]['MAE'] = sum(mae_records) / len(mae_records)\n",
    "    eval_dict[model_name]['MSE'] = sum(mse_records) / len(mse_records)\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "    print(eval_dict)\n",
    "    print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae8ac5-401f-41ba-b534-28b01c6f33ad",
   "metadata": {
    "id": "9eae8ac5-401f-41ba-b534-28b01c6f33ad",
    "outputId": "87ab2a72-20f1-4e70-e78d-68bcdbcdf06b"
   },
   "outputs": [],
   "source": [
    "model = eval_model_multi(DilatedCNN, 'Dilated CNN for alpha forecasting', epochs=10, input_horizon=input_horizon, output_horizon=output_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87722d54-942d-483f-b6d8-7a9b4651fe24",
   "metadata": {
    "id": "87722d54-942d-483f-b6d8-7a9b4651fe24"
   },
   "outputs": [],
   "source": [
    "dl_iteration = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb64cfa-fac6-4280-ac65-ba8fa525d461",
   "metadata": {
    "id": "3cb64cfa-fac6-4280-ac65-ba8fa525d461"
   },
   "outputs": [],
   "source": [
    "sample = next(dl_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59302e4-551c-45c9-bb2c-6806ec493cf3",
   "metadata": {
    "id": "d59302e4-551c-45c9-bb2c-6806ec493cf3"
   },
   "outputs": [],
   "source": [
    "inp, tar = sample\n",
    "pred = model.forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916a1ff-e072-419b-b36d-c79692800258",
   "metadata": {
    "id": "0916a1ff-e072-419b-b36d-c79692800258",
    "outputId": "d368c43f-2434-42b8-b3bf-3d36a52b1c79"
   },
   "outputs": [],
   "source": [
    "for i, t, p in zip(inp, tar, pred):\n",
    "    df_1 = pd.DataFrame({\n",
    "        'true value': i.data.cpu().numpy()[0]\n",
    "    })\n",
    "    df_2 = pd.DataFrame({\n",
    "        'true value': t.data.cpu().numpy(),\n",
    "        'predicted value': p.data.cpu().numpy()\n",
    "    })\n",
    "    df_merged = pd.concat([df_1, df_2], ignore_index=True)\n",
    "    df_merged.plot(figsize=(20, 5), style='.-')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
